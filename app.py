# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jP2T8CvdaNb2fBz2uikf4yEQ54D9jkOG
"""

from google.colab import files
uploaded = files.upload()

import zipfile
import os

zip_path = "/content/Data-20251126T174334Z-1-001.zip"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content/fruit_detection")

print("Extraction completed!")

import os

dataset_path = "/content/fruit_detection"

for root, dirs, files in os.walk(dataset_path):
    print(root, " --> ", len(files), "files")

import os
import shutil

base = "/content/fruit_detection"


paths = [
    f"{base}/dataset/train/images",
    f"{base}/dataset/train/labels",
    f"{base}/dataset/test/images",
    f"{base}/dataset/test/labels"
]

for p in paths:
    os.makedirs(p, exist_ok=True)


train_path = f"{base}/Data/Train"
for f in os.listdir(train_path):
    src = os.path.join(train_path, f)
    if f.endswith(".jpg") or f.endswith(".png") or f.endswith(".jpeg"):
        shutil.move(src, f"{base}/dataset/train/images/{f}")
    elif f.endswith(".txt"):
        shutil.move(src, f"{base}/dataset/train/labels/{f}")

test_path = f"{base}/Data/Test"
for f in os.listdir(test_path):
    src = os.path.join(test_path, f)
    if f.endswith(".jpg") or f.endswith(".png") or f.endswith(".jpeg"):
        shutil.move(src, f"{base}/dataset/test/images/{f}")
    elif f.endswith(".txt"):
        shutil.move(src, f"{base}/dataset/test/labels/{f}")

print("Dataset organized for YOLO format!")

for root, dirs, files in os.walk("/content/fruit_detection/dataset"):
    print(root, " --> ", len(files), "files")

import os

train_path = "/content/fruit_detection/Data/Train"
test_path = "/content/fruit_detection/Data/Test"

print("Train files:")
for f in sorted(os.listdir(train_path))[:20]:
    print(f)

print("\nTest files:")
for f in sorted(os.listdir(test_path))[:20]:
    print(f)

import os

train_ext = {}
test_ext = {}

for f in os.listdir(train_path):
    ext = f.split(".")[-1]
    train_ext[ext] = train_ext.get(ext, 0) + 1

for f in os.listdir(test_path):
    ext = f.split(".")[-1]
    test_ext[ext] = test_ext.get(ext, 0) + 1

print("Train extensions:", train_ext)
print("Test extensions:", test_ext)

import os

root = "/content/fruit_detection"

image_extensions = (".jpg",".jpeg",".png")

image_files = []
for r, d, f in os.walk(root):
    for file in f:
        if file.lower().endswith(image_extensions):
            image_files.append(os.path.join(r, file))

print("Total images found:", len(image_files))
image_files[:10]

import os
import xml.etree.ElementTree as ET

classes = ["apple", "banana", "orange"]

base = "/content/fruit_detection"
train_xml = f"{base}/Data/Train"
test_xml = f"{base}/Data/Test"

train_labels_out = f"{base}/dataset/train/labels"
test_labels_out = f"{base}/dataset/test/labels"

os.makedirs(train_labels_out, exist_ok=True)
os.makedirs(test_labels_out, exist_ok=True)

def convert_xml_to_yolo(xml_file, output_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()

    size = root.find('size')
    if size is None:
        print("‚ö†Ô∏è Missing <size> tag ‚Üí skipping:", xml_file)
        return False


    try:
        w = int(size.find('width').text)
        h = int(size.find('height').text)
    except:
        print("‚ö†Ô∏è Invalid size ‚Üí skipping:", xml_file)
        return False


    if w == 0 or h == 0:
        print("‚ö†Ô∏è Zero width/height ‚Üí skipping:", xml_file)
        return False

    result_lines = []

    for obj in root.iter('object'):
        name = obj.find('name').text.lower()

        if name not in classes:
            continue

        class_id = classes.index(name)

        bnd = obj.find('bndbox')
        xmin = float(bnd.find('xmin').text)
        ymin = float(bnd.find('ymin').text)
        xmax = float(bnd.find('xmax').text)
        ymax = float(bnd.find('ymax').text)


        x_center = (xmin + xmax) / 2.0 / w
        y_center = (ymin + ymax) / 2.0 / h
        bw = (xmax - xmin) / w
        bh = (ymax - ymin) / h

        result_lines.append(f"{class_id} {x_center} {y_center} {bw} {bh}\n")

    with open(output_file, "w") as f:
        f.writelines(result_lines)

    return True





skipped_train = 0
for xml_name in os.listdir(train_xml):
    if xml_name.endswith(".xml"):
        xml_path = os.path.join(train_xml, xml_name)
        txt_name = xml_name.replace(".xml", ".txt")
        out_path = os.path.join(train_labels_out, txt_name)
        ok = convert_xml_to_yolo(xml_path, out_path)
        if not ok:
            skipped_train += 1




skipped_test = 0
for xml_name in os.listdir(test_xml):
    if xml_name.endswith(".xml"):
        xml_path = os.path.join(test_xml, xml_name)
        txt_name = xml_name.replace(".xml", ".txt")
        out_path = os.path.join(test_labels_out, txt_name)
        ok = convert_xml_to_yolo(xml_path, out_path)
        if not ok:
            skipped_test += 1

print("Conversion complete!")
print("Skipped train XML:", skipped_train)
print("Skipped test XML:", skipped_test)

print("Train labels:", len(os.listdir('/content/fruit_detection/dataset/train/labels')))
print("Test labels:", len(os.listdir('/content/fruit_detection/dataset/test/labels')))

import os

base = "/content/fruit_detection/dataset"

train_images = len([f for f in os.listdir(f'{base}/train/images') if f.endswith(('.jpg', '.png', '.jpeg'))])
train_labels = len([f for f in os.listdir(f'{base}/train/labels') if f.endswith('.txt')])
test_images = len([f for f in os.listdir(f'{base}/test/images') if f.endswith(('.jpg', '.png', '.jpeg'))])
test_labels = len([f for f in os.listdir(f'{base}/test/labels') if f.endswith('.txt')])


print("üìä FINAL DATASET VERIFICATION")

print(f"‚úì Training images: {train_images}")
print(f"‚úì Training labels: {train_labels}")
print(f"‚úì Test images: {test_images}")
print(f"‚úì Test labels: {test_labels}")



print("üìÑ SAMPLE LABEL FILE (YOLO format):")
sample_label = os.listdir(f'{base}/train/labels')[0]
with open(f'{base}/train/labels/{sample_label}', 'r') as f:
    print(f.read())

import yaml


data_yaml_content = {
    'path': '/content/fruit_detection/dataset',
    'train': 'train/images',
    'val': 'test/images',
    'test': 'test/images',
    'nc': 3,
    'names': ['apple', 'banana', 'orange']
}

yaml_path = '/content/fruit_detection/dataset/data.yaml'

with open(yaml_path, 'w') as f:
    yaml.dump(data_yaml_content, f, default_flow_style=False)

print("‚úÖ data.yaml created successfully!")
print("\nContents:")
with open(yaml_path, 'r') as f:
    print(f.read())

!pip install ultralytics

from ultralytics import YOLO
import torch


device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"üöÄ Using device: {device}")

print("Loading YOLOv8m model...")
model = YOLO("yolov8m.pt")
print("‚úÖ Model loaded!")

print("üéØ Starting training with YOLOv8m...")

results = model.train(
    data="/content/fruit_detection/dataset/data.yaml",


    epochs=80,
    imgsz=640,
    batch=4,


    name="yolov8m_final",
    project="/content/runs/detect",


    augment=True,
    auto_augment="randaugment",
    mixup=0.1,
    copy_paste=0.2,


    patience=30,
    workers=2,
    deterministic=True,
    device=device,
)

print("‚úÖ Training completed!")

print("üìä Evaluating model...")

metrics = model.val(
    data="/content/fruit_detection/dataset/data.yaml",
    split='test',
    imgsz=640,
    batch=4,
    device=device,
)

print("‚úÖ Evaluation complete!")

print("FINAL EVALUATION RESULTS")


precision = metrics.box.mp
recall = metrics.box.mr
f1_score = 2 * (precision * recall) / (precision + recall)
map50 = metrics.box.map50
map50_95 = metrics.box.map

print(f"\nüìà Overall Metrics:")
print(f"  Precision:       {precision:.4f} ({precision*100:.2f}%)")
print(f"  Recall:          {recall:.4f} ({recall*100:.2f}%)")
print(f"  F1-Score:        {f1_score:.4f} ({f1_score*100:.2f}%)")
print(f"  mAP@0.5:         {map50:.4f} ({map50*100:.2f}%)")
print(f"  mAP@0.5:0.95:    {map50_95:.4f} ({map50_95*100:.2f}%)")


print("\nTarget Check:")
if map50 >= 0.93:
    print(f"  ‚úÖ mAP@0.5: {map50:.4f} (Target: ‚â•0.93) PASSED")
else:
    print(f"  ‚ö†Ô∏è  mAP@0.5: {map50:.4f} (Target: ‚â•0.93) NEED: {0.93-map50:.4f} more")

if f1_score >= 0.90:
    print(f"  ‚úÖ F1-Score: {f1_score:.4f} (Target: ‚â•0.90) PASSED")
else:
    print(f"  ‚ö†Ô∏è  F1-Score: {f1_score:.4f} (Target: ‚â•0.90) NEED: {0.90-f1_score:.4f} more")

import os

for root, dirs, files in os.walk('/content/runs/detect/'):
    for f in files:
        if 'confusion' in f:
            print(os.path.join(root, f))

from IPython.display import Image as IPImage, display

print("üìä Confusion Matrix (from val run):")
display(IPImage('/content/runs/detect/val/confusion_matrix.png'))

print("üìä Confusion Matrix Normalized (from val run):")
display(IPImage('/content/runs/detect/val/confusion_matrix_normalized.png'))

print("üìä Confusion Matrix (from training):")
display(IPImage('/content/runs/detect/yolov8m_final/confusion_matrix.png'))

print("üìä Confusion Matrix Normalized (from training):")
display(IPImage('/content/runs/detect/yolov8m_final/confusion_matrix_normalized.png'))

print("Running predictions...")

model.predict(
    source="/content/fruit_detection/dataset/test/images",
    imgsz=640,
    conf=0.25,
    save=True,
    project="/content/runs/detect",
    name="yolov8m_predictions",
    exist_ok=True
)

print("‚úÖ Predictions saved to: /content/runs/detect/yolov8m_predictions")

best_model_path = "/content/runs/detect/yolov8m_final/weights/best.pt"

print("\nüíæ Model Information:")
print(f"  Best model: {best_model_path}")
print(f"  Results folder: /content/runs/detect/yolov8m_final/")
print(f"  Predictions: /content/runs/detect/yolov8m_predictions/")

import matplotlib.pyplot as plt
from PIL import Image as PILImage
import os


print("üìä VISUALIZATION: DETECTED BOUNDING BOXES ON TEST IMAGES")



predictions_path = '/content/runs/detect/yolov8m_predictions'


predicted_images = sorted([f for f in os.listdir(predictions_path) if f.endswith(('.jpg', '.png'))])

print(f"\nTotal predictions: {len(predicted_images)}")
print("\nDisplaying all test images with detected bounding boxes:\n")
for i, img_file in enumerate(predicted_images, 1):
    img_path = f'{predictions_path}/{img_file}'


    img = PILImage.open(img_path)


    plt.figure(figsize=(10, 8))
    plt.imshow(img)
    plt.axis('off')
    plt.title(f'Detection Result {i}/{len(predicted_images)}: {img_file}',
              fontsize=12, fontweight='bold')
    plt.tight_layout()
    plt.show()

    print(f"‚úì Displayed: {img_file}")

import shutil
import os

print("EXPORTING TRAINED MODEL")



best_model_path = '/content/runs/detect/yolov8m_final/weights/best.pt'


export_path = '/content/fruit_detection_model.pt'
shutil.copy(best_model_path, export_path)

print(f"\n‚úÖ Model exported to: {export_path}")
print(f"üìä Model size: {os.path.getsize(export_path) / (1024*1024):.2f} MB")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from ultralytics import YOLO
# from PIL import Image
# import numpy as np
# import cv2
# 
# 
# st.set_page_config(
#     page_title="Fruit Detection App",
#     page_icon="üçé",
#     layout="wide"
# )
# 
# 
# st.title("üçéüçåüçä Fruit Object Detection")
# st.write("Upload an image to detect apples, bananas, and oranges!")
# 
# 
# @st.cache_resource
# def load_model():
#     model = YOLO('fruit_detection_model.pt')
#     return model
# 
# model = load_model()
# 
# 
# uploaded_file = st.file_uploader("Choose an image...", type=['jpg', 'jpeg', 'png'])
# 
# if uploaded_file is not None:
# 
#     image = Image.open(uploaded_file)
# 
#     col1, col2 = st.columns(2)
# 
#     with col1:
#         st.subheader("Original Image")
#         st.image(image, use_container_width=True)
# 
# 
#     with st.spinner('Detecting fruits...'):
#         results = model.predict(image, conf=0.25)
# 
# 
#         annotated_image = results[0].plot()
#         annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
# 
#     with col2:
#         st.subheader("Detection Results")
#         st.image(annotated_image, use_container_width=True)
# 
# 
#     st.subheader("üìä Detection Details")
# 
#     detections = results[0].boxes
# 
#     if len(detections) > 0:
#         class_names = ['apple', 'banana', 'orange']
# 
#         for i, box in enumerate(detections):
#             cls = int(box.cls[0])
#             conf = float(box.conf[0])
# 
#             st.write(f"**Object {i+1}:** {class_names[cls].capitalize()} - Confidence: {conf:.2%}")
#     else:
#         st.write("No fruits detected in the image.")
#

# --- Colab Streamlit + Cloudflared Setup ---

# 1Ô∏è‚É£ Install dependencies
!pip install streamlit pandas requests --quiet

# 2Ô∏è‚É£ Download and install cloudflared
!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb
!dpkg -i cloudflared-linux-amd64.deb

# 3Ô∏è‚É£ Kill any old processes
!pkill -f streamlit
!pkill -f cloudflared

# 4Ô∏è‚É£ Run Streamlit app in background and log output
!nohup streamlit run app.py --server.port 8501 --server.headless true > log.txt 2>&1 &

import time
print("‚è≥ Waiting 10 seconds for Streamlit to start...")
time.sleep(10)

# 5Ô∏è‚É£ Check if Streamlit is running
!tail -n 20 log.txt

# 6Ô∏è‚É£ Start Cloudflared tunnel (after Streamlit is up)
!cloudflared tunnel --url http://localhost:8501 --no-autoupdate